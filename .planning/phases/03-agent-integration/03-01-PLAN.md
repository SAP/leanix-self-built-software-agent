---
phase: 03-agent-integration
plan: 01
type: execute
---

<objective>
Pass user-provided discovery context to LLM agents to enhance discovery accuracy.

Purpose: Enable agents to use organization and repository context when making classification and detection decisions.
Output: Updated workflow with context loading, and agent prompts that include context when available.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (dependency graph):
@.planning/phases/01-context-model/01-01-SUMMARY.md
@.planning/phases/02-context-discovery/02-01-SUMMARY.md

# Key files from prior phases:
@src/dto/context_dto.py
@src/services/context_loader.py
@src/nodes/runnables/load_context_runnable.py
@src/dto/state_dto.py

# Files to modify:
@src/workflows/repo_type_workflow.py
@src/nodes/agents/mono_repo_services_inspector_agent.py
@src/nodes/agents/repo_type_agent.py
@src/nodes/agents/tech_stack_agent.py
@src/nodes/agents/languages_service_agent.py

**Tech stack available:** LangChain, LangGraph, structlog
**Established patterns:**
- Prompt interpolation with f-strings
- State flows through workflow via RootRepoState
- Context uses ## headers for LLM clarity
**Constraining decisions:**
- Phase 1: Simple string merge with headers (repo after org for recency weighting)
- Phase 2: CLI override path marked as `<cli-override>` for debugging
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire load_context_runnable into workflow</name>
  <files>src/workflows/repo_type_workflow.py</files>
  <action>
Add the load_context_runnable to the workflow DAG. The runnable should be called AFTER clone_repo_tool_runnable and BEFORE deployment_signals_detection_runnable. This ensures context is available for all downstream agents.

Steps:
1. Import load_context_runnable from src.nodes.runnables.load_context_runnable
2. Add node: `graph.add_node("load_context_runnable", load_context_runnable)`
3. Update edge: Change `clone_repo_tool_runnable` → `deployment_signals_detection_runnable` to `clone_repo_tool_runnable` → `load_context_runnable` → `deployment_signals_detection_runnable`

The runnable is already tested and ready (created in Phase 2). It reads state.local_path and state.repo_root_url, populates state.discovery_context.
  </action>
  <verify>
1. Run `python -c "from src.workflows.repo_type_workflow import generate_repo_type_workflow; g = generate_repo_type_workflow(); print([n for n in g.nodes])"` - should include 'load_context_runnable'
2. Check no import errors or syntax issues
  </verify>
  <done>load_context_runnable appears in workflow graph between clone and deployment detection</done>
</task>

<task type="auto">
  <name>Task 2: Add context injection helper function</name>
  <files>src/utils/context_injection.py</files>
  <action>
Create a utility function that agents can use to inject context into their prompts. This centralizes the formatting logic and handles the case when no context is available.

Create new file `src/utils/context_injection.py`:

```python
"""Utility for injecting user-provided context into agent prompts."""
from __future__ import annotations

from typing import Optional
from src.dto.context_dto import DiscoveryContext


def format_context_for_prompt(context: Optional[DiscoveryContext], max_chars: int = 4000) -> str:
    """Format discovery context for injection into LLM prompts.

    Args:
        context: The DiscoveryContext from state, or None.
        max_chars: Maximum characters to include (prevent token bloat).
                   Default 4000 chars ≈ ~1000 tokens.

    Returns:
        A formatted string ready for prompt injection, or empty string if no context.
        The string includes a clear section header so the LLM understands the context.
    """
    if context is None or not context.merged_context:
        return ""

    merged = context.merged_context.strip()

    # Truncate if too long (protect against token bloat)
    if len(merged) > max_chars:
        merged = merged[:max_chars] + "\n... [context truncated]"

    return f"""
## User-Provided Context
The following context was provided by the user to help with discovery. Use this information to make better decisions about service classification, tech stack detection, and naming conventions.

{merged}

---
"""
```

This function:
- Returns empty string when no context (agents continue to work as before)
- Truncates to prevent token bloat (constraint from PROJECT.md)
- Adds clear header so LLM understands the context section
  </action>
  <verify>
1. Run `python -c "from src.utils.context_injection import format_context_for_prompt; print('OK')"` - no import errors
2. Run `python -c "from src.utils.context_injection import format_context_for_prompt; print(repr(format_context_for_prompt(None)))"` - should print `''`
  </verify>
  <done>context_injection.py exists with format_context_for_prompt function that handles None gracefully and truncates long context</done>
</task>

<task type="auto">
  <name>Task 3: Update mono_repo_services_inspector_agent with context</name>
  <files>src/nodes/agents/mono_repo_services_inspector_agent.py</files>
  <action>
Update the monorepo inspector agent to include user context in its prompt. This agent discovers services in mono-repos, so context about naming patterns and deployment conventions is highly valuable.

Changes:
1. Import the context injection helper: `from src.utils.context_injection import format_context_for_prompt`
2. Before building the prompt, get the context string: `context_section = format_context_for_prompt(state.discovery_context)`
3. Inject the context section AFTER the "## Role" section and BEFORE "## Definition" section

The context section should appear early in the prompt so the LLM considers it when making decisions. Insert after line ~26 (after Role section):

```python
context_section = format_context_for_prompt(state.discovery_context)

prompt = (
    "## Role"
    f"You are a software discovery analyst. Your job is to find deployable self-built software (services/apps/artifacts) inside a single Git monorepo, hosted on {repo_root_url}."
    f"{context_section}"  # Insert here
    """

    ## Definition of "self-built software"
    ...
```

The f-string injection handles the empty case (no change to prompt when no context).
  </action>
  <verify>
Run `python -c "from src.nodes.agents.mono_repo_services_inspector_agent import monorepo_inspector_agent; print('OK')"` - no import errors
  </verify>
  <done>mono_repo_services_inspector_agent imports context helper and injects context into prompt when available</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python -c "from src.workflows.repo_type_workflow import generate_repo_type_workflow; g = generate_repo_type_workflow(); print([n for n in g.nodes])"` includes 'load_context_runnable'
- [ ] `python -c "from src.utils.context_injection import format_context_for_prompt; print('OK')"` - no errors
- [ ] `python -c "from src.nodes.agents.mono_repo_services_inspector_agent import monorepo_inspector_agent; print('OK')"` - no errors
- [ ] No syntax errors in modified files
</verification>

<success_criteria>

- All tasks completed
- load_context_runnable wired into workflow
- Context injection helper created with truncation support
- At least one agent (mono_repo_services_inspector_agent) updated to use context
- No import errors or regressions
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-integration/03-01-SUMMARY.md` with:

# Phase 3 Plan 1: Agent Integration Summary

**[Substantive one-liner]**

## Performance
- Duration: X min
- Tasks: 3
- Files modified: 3

## Accomplishments
- Wired load_context_runnable into workflow DAG
- Created context injection utility with token-aware truncation
- Updated mono_repo_services_inspector_agent with context injection

## Task Commits
Each task was committed atomically:
1. Task 1: [commit hash] (feat)
2. Task 2: [commit hash] (feat)
3. Task 3: [commit hash] (feat)

## Files Created/Modified
- `src/workflows/repo_type_workflow.py` - Added load_context_runnable node
- `src/utils/context_injection.py` - New context formatting utility
- `src/nodes/agents/mono_repo_services_inspector_agent.py` - Context injection in prompt

## Decisions Made
- Context injected after Role section in prompts
- 4000 char limit for context (≈1000 tokens) to prevent bloat
- Truncation with `[context truncated]` marker

## Deviations from Plan
[Note any deviations]

## Issues Encountered
[Note any issues]

## Next Phase Readiness
- Context infrastructure complete
- Additional agents can be updated if needed (repo_type_agent, tech_stack_agent, languages_service_agent)
- Ready for Phase 4: CLI Integration

---
*Phase: 03-agent-integration*
</output>
